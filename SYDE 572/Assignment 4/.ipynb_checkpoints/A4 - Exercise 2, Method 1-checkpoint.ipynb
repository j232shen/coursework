{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6042e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd11419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9ea1d596f255>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y[label].append(torch.tensor(dataset[label].targets[subset_idx][:600]).long())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6000, 32, 32, 1])\n",
      "torch.Size([6000, 32, 32, 1])\n",
      "torch.Size([6000])\n",
      "torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "def resize_batch(imgs):\n",
    "    imgs = imgs.reshape((-1, 28, 28, 1))\n",
    "    resized_imgs = np.zeros((imgs.shape[0], 32, 32, 1))\n",
    "    \n",
    "    for i in range(imgs.shape[0]):\n",
    "        # add 2 pixels of padding to the top, bottom, left, and right\n",
    "        resized_imgs[i, ..., 0] = np.pad(imgs[i, ..., 0], ((2, 2), (2, 2)), mode='constant')\n",
    "    \n",
    "    return resized_imgs\n",
    "\n",
    "root = 'data'\n",
    "classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
    "\n",
    "# load data and select the classes of interest\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# load data\n",
    "labels = ['train', 'test']\n",
    "dataset = {'train': MNIST(root=root, train=True, download=True, transform=transform), \n",
    "            'test': MNIST(root=root, train=False, download=True, transform=transform)}\n",
    "\n",
    "# resize images to (32, 32)\n",
    "for label in labels:\n",
    "    dataset[label].data = resize_batch(dataset[label].data.numpy())\n",
    "\n",
    "# create dicts for storing sampled data\n",
    "X = {'train': [], 'test': []}\n",
    "y = {'train': [], 'test': []}\n",
    "\n",
    "# for the training and test datasets\n",
    "for label in labels:\n",
    "    # sample 600 points for each class\n",
    "    for c in classes:\n",
    "        subset_idx = torch.isin(dataset[label].targets, torch.as_tensor(c))\n",
    "        # convert to tensor\n",
    "        X[label].append(torch.tensor(dataset[label].data[subset_idx][:600]).float())\n",
    "        y[label].append(torch.tensor(dataset[label].targets[subset_idx][:600]).long()) \n",
    "    \n",
    "    # concatenate along the first dimension\n",
    "    X[label] = torch.cat(X[label], dim=0)\n",
    "    y[label] = torch.cat(y[label], dim=0)    \n",
    "    \n",
    "print(X['train'].shape)\n",
    "print(X['test'].shape)\n",
    "print(y['train'].shape)\n",
    "print(y['test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b54ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG11 model\n",
    "class VGG11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1. Conv(001, 064, 3, 1, 1) - BatchNorm(064) - ReLU - MaxPool(2, 2)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(64)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.maxPool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 2. Conv(064, 128, 3, 1, 1) - BatchNorm(128) - ReLU - MaxPool(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.maxPool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 3. Conv(128, 256, 3, 1, 1) - BatchNorm(256) - ReLU\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(256)\n",
    "        self.act3 = nn.ReLU()\n",
    "        \n",
    "        # 4. Conv(256, 256, 3, 1, 1) - BatchNorm(256) - ReLU - MaxPool(2, 2)\n",
    "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm4 = nn.BatchNorm2d(256)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.maxPool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 5. Conv(256, 512, 3, 1, 1) - BatchNorm(512) - ReLU\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm5 = nn.BatchNorm2d(512)\n",
    "        self.act5 = nn.ReLU()\n",
    "        \n",
    "        # 6. Conv(512, 512, 3, 1, 1) - BatchNorm(512) - ReLU - MaxPool(2, 2)\n",
    "        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm6 = nn.BatchNorm2d(512)\n",
    "        self.act6 = nn.ReLU()\n",
    "        self.maxPool6 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 7. Conv(512, 512, 3, 1, 1) - BatchNorm(512) - ReLU\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm7 = nn.BatchNorm2d(512)\n",
    "        self.act7 = nn.ReLU()\n",
    "        \n",
    "        # 8. Conv(512, 512, 3, 1, 1) - BatchNorm(512) - ReLU - MaxPool(2, 2)\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.BatchNorm8 = nn.BatchNorm2d(512)\n",
    "        self.act8 = nn.ReLU()\n",
    "        self.maxPool8 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 9. Linear(0512, 4096) - ReLU - Dropout(0.5)\n",
    "        self.hidden9 = nn.Linear(512, 4096)\n",
    "        self.act9 = nn.ReLU()\n",
    "        self.drop9 = nn.Dropout(0.5)\n",
    "        \n",
    "        # 10. Linear(4096, 4096) - ReLU - Dropout(0.5)\n",
    "        self.hidden10 = nn.Linear(4096, 4096)\n",
    "        self.act10 = nn.ReLU()\n",
    "        self.drop10 = nn.Dropout(0.5)\n",
    "        \n",
    "        # 11. Linear(4096, 10)\n",
    "        self.output = nn.Linear(4096, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # adjust input shape: reshape using view\n",
    "        x = x.view(x.size(0), 1, 32, 32)\n",
    "    \n",
    "        # convolutional layers\n",
    "        x = self.maxPool1(self.act1(self.BatchNorm1(self.conv1(x))))\n",
    "        x = self.maxPool2(self.act2(self.BatchNorm2(self.conv2(x))))\n",
    "        x = self.act3(self.BatchNorm3(self.conv3(x)))\n",
    "        x = self.maxPool4(self.act4(self.BatchNorm4(self.conv4(x))))\n",
    "        x = self.act5(self.BatchNorm5(self.conv5(x)))\n",
    "        x = self.maxPool6(self.act6(self.BatchNorm6(self.conv6(x))))\n",
    "        x = self.act7(self.BatchNorm7(self.conv7(x)))\n",
    "        x = self.maxPool8(self.act8(self.BatchNorm8(self.conv8(x))))\n",
    "        \n",
    "        # flatten output of convolutional layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fully connected layers\n",
    "        x = self.drop9(self.act9(self.hidden9(x)))\n",
    "        x = self.drop10(self.act10(self.hidden10(x)))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.4606, TIme elapsed: 57.3468s\n",
      "Epoch [2/10], Loss: 2.3006, TIme elapsed: 64.1294s\n",
      "Epoch [3/10], Loss: 2.3402, TIme elapsed: 59.3136s\n",
      "Epoch [4/10], Loss: 2.3610, TIme elapsed: 70.9664s\n",
      "Epoch [5/10], Loss: 2.3690, TIme elapsed: 76.8668s\n",
      "Epoch [6/10], Loss: 2.3719, TIme elapsed: 57.4869s\n",
      "Epoch [7/10], Loss: 2.3729, TIme elapsed: 60.7021s\n",
      "Epoch [8/10], Loss: 2.3733, TIme elapsed: 60.0297s\n",
      "Epoch [9/10], Loss: 2.3734, TIme elapsed: 61.4850s\n",
      "Epoch [10/10], Loss: 2.3734, TIme elapsed: 64.7037s\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model, loss function, and optimizer\n",
    "model = VGG11()\n",
    "# print(model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "n_epochs = 10 \n",
    "batch_size = 64\n",
    "\n",
    "# grabbing training data\n",
    "x = X['train']\n",
    "y = y['train']\n",
    "\n",
    "# gradient descent to train\n",
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Epoch [{epoch + 1}/{n_epochs}], Loss: {loss.item():.4f}, Time elapsed: {(end - start):.4f}s')\n",
    "\n",
    "# compute accuracy\n",
    "y_pred = model(x)\n",
    "_, predicted = torch.max(y_pred, dim=1)\n",
    "accuracy = (predicted == y).float().mean()\n",
    "print(f'Accuracy = {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14216d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
